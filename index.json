[{"content":"Hi everyone (if someone\u0026rsquo;s there). Extracting text from images has never been easier, thanks to advanced AI models like Llama 3.2 Vision. In this guide, weâ€™ll walk through building a simple yet powerful OCR (Optical Character Recognition) tool using Python, Streamlit, and Ollamaâ€™s AI models.\nWhy Use Llama 3.2 Vision for OCR? Unlike traditional OCR methods, which rely on predefined character recognition techniques, Llama 3.2 Vision leverages AI to not only extract text but also present it in a structured and readable format. This means better accuracy, automatic formatting, and ease of use.\nUnderstanding the Code This application is built using Streamlit, making it interactive and user-friendly and easy to run locally. Letâ€™s break down how it works:\nConfiguring the Streamlit Page We start by defining the page title, icon, and layout:\nst.set_page_config( page_title=\u0026#34;Llama OCR\u0026#34;, page_icon=\u0026#34;ðŸ¦™\u0026#34;, layout=\u0026#34;wide\u0026#34;, initial_sidebar_state=\u0026#34;expanded\u0026#34; ) This ensures a wide layout with an expanded sidebar, making navigation smooth.\nUploading an Image Users can upload images through the sidebar. We\u0026rsquo;ll use st.file_uploader() to allow image selection.\nuploaded_file = st.file_uploader(\u0026#34;Choose an image...\u0026#34;, type=[\u0026#39;png\u0026#39;, \u0026#39;jpg\u0026#39;, \u0026#39;jpeg\u0026#39;]) Once an image is uploaded, itâ€™s displayed in the sidebar using:\nimage = Image.open(uploaded_file) st.image(image, caption=\u0026#34;Uploaded Image\u0026#34;) Extracting Text from the Image When the user clicks the Extract Text button, the image is sent to the Llama 3.2 Vision model for processing:\nresponse = ollama.chat( model=\u0026#39;llama3.2-vision\u0026#39;, messages=[{ \u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#34;\u0026#34;\u0026#34;Analyze the text in the provided image. Extract all readable content and present it in a structured Markdown format.\u0026#34;\u0026#34;\u0026#34;, \u0026#39;images\u0026#39;: [uploaded_file.getvalue()] }] ) The extracted text is stored in st.session_state so it persists across interactions.\nDisplaying the Extracted Text Once the processing is complete, the extracted text is displayed in the main content area using:\nst.markdown(st.session_state[\u0026#39;ocr_result\u0026#39;]) If no text has been extracted yet, an informational message guides the user.\nRunning the Application locally Run these following commands in your terminal:\nClone the repository: git clone https://github.com/piktx/local-ocr.git cd local-ocr Install dependencies: pip install -r requirements.txt Start Ollama service: ollama serve Launch the Streamlit app: streamlit run app.py This will start a local server, and the tool will be accessible via the displayed URL (usually http://localhost:8501). Final Thoughts With just a few lines of code, you can built an AI-powered OCR tool that can extract structured text from images with impressive accuracy and the best part is, you can do all this on your local machine. Whether you need to digitize documents, extract notes, or process scanned images, Llama 3.2 Vision provides a seamless solution.\nLast but not the least, If you liked this project, don\u0026rsquo;t forget to give it a star on Github\n","permalink":"https://piktx.github.io/posts/llama-ocr/","summary":"\u003cp\u003eHi everyone (if someone\u0026rsquo;s there). Extracting text from images has never been easier, thanks to advanced AI models like Llama 3.2 Vision. In this guide, weâ€™ll walk through building a simple yet powerful OCR (Optical Character Recognition) tool using Python, Streamlit, and Ollamaâ€™s AI models.\u003c/p\u003e\n\u003ch3 id=\"why-use-llama-32-vision-for-ocr\"\u003eWhy Use Llama 3.2 Vision for OCR?\u003c/h3\u003e\n\u003cp\u003eUnlike traditional OCR methods, which rely on predefined character recognition techniques, Llama 3.2 Vision leverages AI to not only extract text but also present it in a structured and readable format. This means better accuracy, automatic formatting, and ease of use.\u003c/p\u003e","title":"Extract Text from Images using Llama OCR"},{"content":"Hi everyone (if someoneâ€™s there). There\u0026rsquo;s something magical about teaching computers to understand not just our words, but our intent. I recently made a chatbot with Google\u0026rsquo;s Gemini 2.0 Flash model - and the best part? You can create it too. Let me walk you through this project that blend cutting-edge AI with practical applications.\n1. The Spreadsheet Whisperer Behind the Curtain This chatbot project came from a simple question: \u0026ldquo;Why can\u0026rsquo;t I just make a chatbot to ask questions about any sort of data I give it and ask questions about it?\u0026rdquo; Here\u0026rsquo;s how it works:\n# The brain of the operation llm = Ollama(model=\u0026#34;llama3.2-vision\u0026#34;) embed_model = HuggingFaceEmbedding(model_name=\u0026#34;BAAI/bge-large-en-v1.5\u0026#34;) # Custom prompt engineering qa_prompt = ( \u0026#34;Context information:\\n{context_str}\\n\u0026#34; \u0026#34;Answer like a data analyst friend: {query_str}\\n\u0026#34; \u0026#34;If unsure, just say so - no guessing!\u0026#34; ) The magic happens in three layers:\nDocument Alchemy: Converts tables into searchable knowledge using DoclingReader\nContextual Understanding: BAAI embeddings create \u0026ldquo;mental maps\u0026rdquo; of data relationships\nConversational Interface: Streamlit provides the chat interface we all recognize\n2. Seeing Through AI\u0026rsquo;s Eyes: Multimodal Chat When Words Meet Images This project answers: \u0026ldquo;What if I could show pictures AND ask questions?\u0026rdquo; Using Google\u0026rsquo;s Gemini 2.0 Flash model:\ndef initialize_gemini(): # Secure API handling genai.configure(api_key=decoded_key) return genai.GenerativeModel(\u0026#34;gemini-2.0-flash-exp\u0026#34;) # Handling multimodal input if uploaded_file: inputs.append(Image.open(uploaded_file)) response = model.generate_content(inputs) This implementation does something remarkable:\nSeamless blending of visual and textual understanding\nContext-aware responses that reference image content\nStreaming interface that feels truly conversational\nI particularly love how it handles follow-up questions about previously uploaded images.\nMaking It Work: A Developer\u0026rsquo;s Journey Prerequisites Python 3.10+ environment Ollama installed and running 8GB+ RAM (16GB recommended) Installation Steps Clone the repository: git clone https://github.com/piktx/flash-mutimodal-chatbot.git cd flash-mutimodal-chatbot Install dependencies: pip install -r requirements.txt Start Ollama service: ollama serve Launch the Streamlit app: streamlit run app.py The interface will automatically open in your default browser at localhost:8501. Final Thoughts This project demonstrate how accessible AI has become. Whether you\u0026rsquo;re:\nA business user tired of pivot tables or\nA developer exploring multimodal AI or\nAn AI enthusiast curious about real applications\nThere\u0026rsquo;s never been a better time to experiment.\nLast but not the least, If you liked this project, don\u0026rsquo;t forget to give it a star on Github\n","permalink":"https://piktx.github.io/posts/gemini-flash-chatbot/","summary":"\u003cp\u003eHi everyone (if someoneâ€™s there). There\u0026rsquo;s something magical about teaching computers to understand not just our words, but our \u003cem\u003eintent\u003c/em\u003e. I recently made a chatbot with Google\u0026rsquo;s Gemini 2.0 Flash model - and the best part? You can create it too. Let me walk you through this project that blend cutting-edge AI with practical applications.\u003c/p\u003e\n\u003ch2 id=\"1-the-spreadsheet-whisperer\"\u003e1. The Spreadsheet Whisperer\u003c/h2\u003e\n\u003ch3 id=\"behind-the-curtain\"\u003eBehind the Curtain\u003c/h3\u003e\n\u003cp\u003eThis chatbot project came from a simple question: \u0026ldquo;Why can\u0026rsquo;t I just make a chatbot to \u003cem\u003eask questions\u003c/em\u003e about any sort of data I give it and ask questions about it?\u0026rdquo; Here\u0026rsquo;s how it works:\u003c/p\u003e","title":"Building Conversational AI Experiences: From Spreadsheets to Multimodal Magic"},{"content":"Hi everyone (if someone\u0026rsquo;s there). In today\u0026rsquo;s data-driven world, Excel spreadsheets remain the workhorse of business analytics. But what if you could chat with your financial reports or sales data like you\u0026rsquo;d converse with a colleague? In this post, we\u0026rsquo;ll explore how I built a completely local AI assistant that understands Excel files using cutting-edge open-source tools.\nThe Tech Stack Breakdown This program combines several powerful technologies=\nOllama for running the Llama3.2-vision model locally Hugging Face embeddings for document understanding Streamlit for the chat interface LlamaIndex for RAG (Retrieval-Augmented Generation) implementation The magic happens in three key phases:\nDocument Processing: Excel files are parsed using DoclingReader AI Brain: Local LLM processing with custom knowledge integration Conversation: Natural language interface powered by Streamlit Code Walkthrough: How It All Connects Let\u0026rsquo;s peek under the hood at the key components:\nThe Document Processing Engine # Custom reader for Excel files reader = DoclingReader() loader = SimpleDirectoryReader( input_dir=temp_dir, file_extractor={\u0026#34;.xlsx\u0026#34;: reader}, ) This code converts Excel tables into structured markdown, preserving crucial relationships between columns and rows. The MarkdownNodeParser then breaks this content into digestible chunks for our AI model.\nLocal AI Configuration # Local LLM setup llm = Ollama(model=\u0026#34;llama3.2-vision\u0026#34;, request_timeout=120.0) # Semantic understanding embed_model = HuggingFaceEmbedding( model_name=\u0026#34;BAAI/bge-large-en-v1.5\u0026#34;, trust_remote_code=True ) We\u0026rsquo;re using quantized models that balance performance with hardware requirements. The BAAI embeddings create a mathematical \u0026ldquo;map\u0026rdquo; of document content, while Llama3 handles reasoning.\nThe Conversation Engine # Custom prompt template qa_prompt_tmpl_str = ( \u0026#34;Context information is below.\\n\u0026#34; \u0026#34;Given the context information above I want you to think step by step...\u0026#34; ) This carefully crafted prompt forces the AI to show its work while maintaining concise answers. The streaming response implementation creates that familiar \u0026ldquo;typing\u0026rdquo; effect seen in commercial chatbots.\nRunning the Assistant Locally Prerequisites Python 3.10+ environment Ollama installed and running 8GB+ RAM (16GB recommended) Installation Steps Clone the repository: git clone https://github.com/piktx/excel-rag.git cd excel-rag Install dependencies: pip install -r requirements.txt Start Ollama service: ollama serve Launch the Streamlit app: streamlit run app.py The interface will automatically open in your default browser at localhost:8501. Key Benefits Complete Data Privacy: All processing stays on your machine\nCustomizable: Swap models or add new file types easily\nNo Cloud Costs: Runs on existing hardware\nFinal Thoughts While commercial AI solutions dominate headlines, this project demonstrates the remarkable capabilities of open-source. The ability to chat with complex spreadsheets opens new possibilities for data analysis while maintaining strict data control.\nLast but not the least, If you liked this project, don\u0026rsquo;t forget to give it a star on Github\n","permalink":"https://piktx.github.io/posts/rag-over-excel/","summary":"\u003cp\u003eHi everyone (if someone\u0026rsquo;s there). In today\u0026rsquo;s data-driven world, Excel spreadsheets remain the workhorse of business analytics. But what if you could chat with your financial reports or sales data like you\u0026rsquo;d converse with a colleague? In this post, we\u0026rsquo;ll explore how I built a completely local AI assistant that understands Excel files using cutting-edge open-source tools.\u003c/p\u003e\n\u003ch2 id=\"the-tech-stack-breakdown\"\u003eThe Tech Stack Breakdown\u003c/h2\u003e\n\u003cp\u003eThis program combines several powerful technologies=\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOllama\u003c/strong\u003e for running the Llama3.2-vision model locally\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHugging Face\u003c/strong\u003e embeddings for document understanding\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStreamlit\u003c/strong\u003e for the chat interface\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLlamaIndex\u003c/strong\u003e for RAG (Retrieval-Augmented Generation) implementation\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe magic happens in three key phases:\u003c/p\u003e","title":"Chat with Excel files using RAG"},{"content":"Hi everyone (if someone\u0026rsquo;s there). In this post, I\u0026rsquo;ll walk you through the core components of a smart data analysis platform built with Streamlit, Groq API, and PandasAI. Instead of overwhelming you with one huge block of code, I\u0026rsquo;ll break the project into smaller, digestible chunks. This approach makes it easier to understand how each part works and how they all come together to create an interactive, AI-powered data exploration tool.\nSetting Up the Environment The project kicks off by configuring the Streamlit page and applying custom styling. This snippet sets the layout and introduces a fresh look with minimal CSS:\nimport streamlit as st # Configure the Streamlit page with a wide layout and a custom title st.set_page_config(page_title=\u0026#34;Smart Data Analysis with Groq API and PandasAI\u0026#34;, layout=\u0026#34;wide\u0026#34;) # Custom styling for a clean and modern interface st.markdown(\u0026#34;\u0026#34;\u0026#34; \u0026lt;style\u0026gt; body { background-color: #F5F5F5; } .stButton button { background-color: #0072C6; color: #FFFFFF; } \u0026lt;/style\u0026gt; \u0026#34;\u0026#34;\u0026#34;, unsafe_allow_html=True) This simple setup ensures the application looks consistent and inviting from the moment it loads.\nAuthenticating with the Groq API Before diving into data analysis, the app needs to authenticate with the Groq API. This is achieved through a small, efficient function that leverages caching to speed up repeated accesses:\nfrom langchain_groq.chat_models import ChatGroq @st.cache_resource def authenticate_groq(api_key): # Returns a ChatGroq instance for AI-driven data analysis return ChatGroq(model_name=\u0026#34;llama-3.3-70b-versatile\u0026#34;, api_key=api_key) Users enter their API key via a sidebar widget, and if the key is valid, the application connects to the AI model. This step is crucial for unlocking the advanced features of the platform.\nUploading and Previewing Data Next, the app supports uploading CSV or Excel files. Once a file is uploaded, the data is read into a Pandas DataFrame and a preview is displayed:\nimport pandas as pd # Load data based on the selected file type if file_type == \u0026#34;CSV\u0026#34;: data = pd.read_csv(uploaded_file) else: data = pd.read_excel(uploaded_file, engine=\u0026#34;openpyxl\u0026#34;) # Display the first few rows of the datase st.write(data.head()) This snippet provides users with an immediate glimpse into their data, including key details like the dataset\u0026rsquo;s shape and data types, ensuring they know what they\u0026rsquo;re working with.\nAI-Driven Query Processing The heart of the platform lies in its ability to process natural language queries. Using PandasAI\u0026rsquo;s SmartDataframe, the app converts plain-English questions into actionable insights or visualizations:\nfrom pandasai import SmartDataframe import time # Create a SmartDataframe that integrates AI capabilities df_groq = SmartDataframe(data, config={\u0026#39;llm\u0026#39;: groq_llm}) # Process the user\u0026#39;s query and capture the response time if query: start_time = time.time() response = df_groq.chat(query) end_time = time.time() st.write(response) st.success(f\u0026#34;Query processed in {end_time - start_time:.2f} seconds.\u0026#34;) This section highlights how the application handles a user\u0026rsquo;s query by communicating with the AI model and then delivering insights, whether as text or interactive visualizations.\nInstallation and Setup Technical Requirements Before beginning, ensure your system has:\nPython 3.9 or newer Valid Groq API key Basic familiarity with command line operations Step-by-Step Implementation Guide Begin by cloning the repository from GitHub: git clone https://github.com/piktx/markai-rag.git cd markai-rag Install the required Python packages using pip: pip install -r requirements.txt Create your environment file: echo \u0026#34;GROQ_API_KEY=your_key_here\u0026#34; \u0026gt; .env Launch the Streamlit interface: streamlit run app.py The interface will automatically open in your default browser at localhost:8501. Final Thoughts By breaking the project into these manageable code chunks, you can clearly see how each component contributes to the overall functionality of the platform. This modular approach not only simplifies understanding but also makes it easier to modify and extend each part as needed.\nThe combination of Streamlit\u0026rsquo;s interactivity, Groq API\u0026rsquo;s AI capabilities, and PandasAI\u0026rsquo;s natural language processing creates a robust tool that transforms raw data into actionable insights. I hope this breakdown inspires you to explore similar integrations in your own projects. Happy coding and data exploring!\nLast but not the least, If you liked this project, don\u0026rsquo;t forget to give it a star on Github\n","permalink":"https://piktx.github.io/posts/markai-rag/","summary":"\u003cp\u003eHi everyone (if someone\u0026rsquo;s there). In this post, I\u0026rsquo;ll walk you through the core components of a smart data analysis platform built with Streamlit, Groq API, and PandasAI. Instead of overwhelming you with one huge block of code, I\u0026rsquo;ll break the project into smaller, digestible chunks. This approach makes it easier to understand how each part works and how they all come together to create an interactive, AI-powered data exploration tool.\u003c/p\u003e","title":"Smart Data Analysis with Groq API and PandasAI: Breaking Down the Code"},{"content":"Hi everyone (if someoneâ€™s there). In the evolving landscape of AI-powered content creation, this news generator represents a significant leap forward. By combining CrewAI\u0026rsquo;s multi-agent framework with Cohere\u0026rsquo;s powerful Command R7B language model, the system automates the entire process of researching and writing comprehensive articles on any given topic. Let\u0026rsquo;s explore how this innovative application works and how you can implement it yourself.\nHow the System Works The application follows a sophisticated two-stage process that mimics human journalistic workflows. First, a Senior Research Analyst agent scours the web using SerperDev\u0026rsquo;s search API, collecting and verifying information from multiple sources. This agent acts like a digital investigative reporter, checking facts and cross-referencing data to ensure accuracy.\nThe collected research then passes to a Content Writer agent, which functions as an experienced journalist. This component synthesizes the raw information into a coherent narrative, maintaining proper citations while ensuring readability. The final output is a well-structured markdown document complete with introduction, body sections, and proper references. Below is the whole workflow of this project: Key Features and Capabilities What makes this system particularly impressive is its ability to handle complex research tasks while maintaining narrative flow. The AI can process technical information from academic papers, news articles, and statistical reports, then transform it into accessible content suitable for general audiences. A unique temperature control slider allows users to adjust the creativity vs. factual accuracy balance, making it adaptable for different writing styles.\nThe built-in citation system ensures transparency by automatically linking claims to their sources. When testing the system, we found it particularly effective at generating technology explainers and current event analyses, though it performs well across most non-specialist topics.\nInstallation and Setup Technical Requirements Before beginning, ensure your system has:\nPython 3.9 or newer Valid API keys for Cohere and SerperDev Basic familiarity with command line operations Step-by-Step Implementation Guide Begin by cloning the repository from GitHub: git clone https://github.com/piktx/ai-news-gen.git cd ai-news-gen Install the required Python packages using pip: pip install -r requirements.txt Create your environment file: echo \u0026#34;COHERE_API_KEY=your_key_here\u0026#34; \u0026gt; .env echo \u0026#34;SERPER_API_KEY=your_key_here\u0026#34; \u0026gt;\u0026gt; .env Launch the Streamlit interface: streamlit run app.py The interface will automatically open in your default browser at localhost:8501.\nUsing the News Generator Once the application is running, you\u0026rsquo;ll be greeted by a clean web interface. The left sidebar contains all controls - simply enter your topic in the text area, adjust the creativity slider if desired, and click the prominent generate button.\nEthical Considerations and Limitations While impressive, users should be aware of the system\u0026rsquo;s limitations. The AI occasionally misses nuanced context in highly technical subjects and should always be fact-checked before publication.\nIt\u0026rsquo;s crucial to remember this tool augments rather than replaces human journalists. The ideal workflow uses AI-generated drafts as starting points for professional writers to refine and enhance.\nFinal thoughts This AI news generator demonstrates the remarkable potential of modern language models when combined with thoughtful system design. By automating the research and initial drafting process, it allows human writers to focus on high-value tasks like analysis and storytelling.\nLast but not the least, If you liked this project, don\u0026rsquo;t forget to give it a star on Github\n","permalink":"https://piktx.github.io/posts/ai-news-gen/","summary":"\u003cp\u003eHi everyone (if someoneâ€™s there). In the evolving landscape of AI-powered content creation, this news generator represents a significant leap forward. By combining CrewAI\u0026rsquo;s multi-agent framework with Cohere\u0026rsquo;s powerful Command R7B language model, the system automates the entire process of researching and writing comprehensive articles on any given topic. Let\u0026rsquo;s explore how this innovative application works and how you can implement it yourself.\u003c/p\u003e\n\u003ch2 id=\"how-the-system-works\"\u003eHow the System Works\u003c/h2\u003e\n\u003cp\u003eThe application follows a sophisticated two-stage process that mimics human journalistic workflows. First, a Senior Research Analyst agent scours the web using SerperDev\u0026rsquo;s search API, collecting and verifying information from multiple sources. This agent acts like a digital investigative reporter, checking facts and cross-referencing data to ensure accuracy.\u003c/p\u003e","title":"AI News Generator app"},{"content":"Hello everyone (if someone\u0026rsquo;s there). This project ðŸ¦™ Llama OCR - Image Text Extraction Tool was made to show you how to run Llama 3.2 Vision Model on your own computer.\nFor more information on the working of this project and how to run this program on your local machine, read this blog\n","permalink":"https://piktx.github.io/projects/llama-ocr/","summary":"\u003cp\u003eHello everyone (if someone\u0026rsquo;s there). This project \u003cstrong\u003e\u003ca href=\"https://github.com/piktx/local-ocr\"\u003eðŸ¦™ Llama OCR - Image Text Extraction Tool\u003c/a\u003e\u003c/strong\u003e was made to show you how to run \u003cstrong\u003eLlama 3.2 Vision Model\u003c/strong\u003e on your own computer.\u003c/p\u003e\n\u003cp\u003eFor more information on the working of this project and how to run this program on your local machine, read this \u003cstrong\u003e\u003ca href=\"https://pktx.xyz/posts/llama-ocr\"\u003eblog\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e","title":"ðŸ¦™ Llama OCR - Image Text Extraction Tool"},{"content":"Hello everyone (if someone\u0026rsquo;s there). This project Gemini Flash 2.0 MultiModal Chatbot was made to check how this new model by Google works. Nothing serious.\nFor more information on the working of this project and how to run this program on your local machine, read this blog\n","permalink":"https://piktx.github.io/projects/gemini-flash-chatbot/","summary":"\u003cp\u003eHello everyone (if someone\u0026rsquo;s there). This project \u003cstrong\u003e\u003ca href=\"https://github.com/piktx/flash-mutimodal-chatbot\"\u003eGemini Flash 2.0 MultiModal Chatbot\u003c/a\u003e\u003c/strong\u003e was made to check how this new model by Google works. Nothing serious.\u003c/p\u003e\n\u003cp\u003eFor more information on the working of this project and how to run this program on your local machine, read this \u003cstrong\u003e\u003ca href=\"https://pktx.xyz/posts/gemini-flash-chatbot\"\u003eblog\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e","title":"Gemini Flash 2.0 MultiModal Chatbot"},{"content":"Hello everyone (if someone\u0026rsquo;s there). This project, RAG over Excel with IBM Dockling and Llama 3.2, was made to help you extract details from an Excel file using some of the best technologies that IBM and Meta made, namely, respectively, Docling and Llama 3.2 Model on your own computer.\nFor more information on the workings of this project and how to run this program on your local machine, read this blog\n","permalink":"https://piktx.github.io/projects/rag-over-excel/","summary":"\u003cp\u003eHello everyone (if someone\u0026rsquo;s there). This project, \u003cstrong\u003e\u003ca href=\"https://github.com/piktx/excel-rag\"\u003eRAG over Excel with IBM Dockling and Llama 3.2\u003c/a\u003e\u003c/strong\u003e, was made to help you extract details from an \u003cstrong\u003eExcel\u003c/strong\u003e file using some of the best technologies that IBM and Meta made, namely, respectively, \u003cstrong\u003eDocling\u003c/strong\u003e and \u003cstrong\u003eLlama 3.2 Model\u003c/strong\u003e on your own computer.\u003c/p\u003e\n\u003cp\u003eFor more information on the workings of this project and how to run this program on your local machine, read this \u003cstrong\u003e\u003ca href=\"https://pktx.xyz/posts/rag-over-excel\"\u003eblog\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e","title":"RAG over Excel with IBM Docling and Llama 3.2"},{"content":"Hello everyone (if someone\u0026rsquo;s there). This project, MarkAI RAG, was made using GROQ API, Microsoft MarkItDown and PandasAI for smart document querying (RAG) on your own computer.\nFor more information on the working of this project and how to run this program on your local machine, read this blog\n","permalink":"https://piktx.github.io/projects/markai-rag/","summary":"\u003cp\u003eHello everyone (if someone\u0026rsquo;s there). This project, \u003cstrong\u003e\u003ca href=\"https://github.com/piktx/markai-rag\"\u003eMarkAI RAG\u003c/a\u003e\u003c/strong\u003e, was made using \u003cstrong\u003eGROQ API\u003c/strong\u003e, \u003cstrong\u003eMicrosoft MarkItDown\u003c/strong\u003e and \u003cstrong\u003ePandasAI\u003c/strong\u003e for smart document querying (RAG) on your own computer.\u003c/p\u003e\n\u003cp\u003eFor more information on the working of this project and how to run this program on your local machine, read this \u003cstrong\u003e\u003ca href=\"https://pktx.xyz/posts/markai-rag\"\u003eblog\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e","title":"MarkAI RAG"},{"content":"Hello everyone (if someone\u0026rsquo;s there). This project, AI NEWS GENERATOR, will help you generate amazing and comprehensive news and/or blog posts using multiple Large Language Models.\nFor more information on the working of this project and how to run this program on your local machine, read this blog\n","permalink":"https://piktx.github.io/projects/ai-news-gen/","summary":"\u003cp\u003eHello everyone (if someone\u0026rsquo;s there). This project, \u003cstrong\u003e\u003ca href=\"https://github.com/piktx/ai-news-gen\"\u003eAI NEWS GENERATOR\u003c/a\u003e\u003c/strong\u003e, will help you generate amazing and comprehensive news and/or blog posts using multiple \u003cstrong\u003eLarge Language Models\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eFor more information on the working of this project and how to run this program on your local machine, read this \u003cstrong\u003e\u003ca href=\"https://pktx.xyz/posts/ai-news-gen\"\u003eblog\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e","title":"AI NEWS GENERATOR"},{"content":"Jan 2023 - Jan 2024\nDescription Analyzed trends and patterns in customer behaviors, improving insights by 30%. Designed surveys and polls, increasing response rates by 25%. Built end-to-end predictive models using ML algorithms, achieving 85% prediction accuracy. Streamlined ETL processes, improving data pipeline stability and reducing errors by 15%. ","permalink":"https://piktx.github.io/experience/bainbridge/","summary":"\u003cp\u003e\u003cem\u003eJan 2023 - Jan 2024\u003c/em\u003e\u003c/p\u003e\n\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAnalyzed trends and patterns in customer behaviors, improving insights by \u003cstrong\u003e30%\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eDesigned surveys and polls, increasing response rates by \u003cstrong\u003e25%\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eBuilt end-to-end predictive models using ML algorithms, achieving \u003cstrong\u003e85% prediction accuracy\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eStreamlined ETL processes, improving data pipeline stability and reducing errors by \u003cstrong\u003e15%\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e","title":"Data Engineer"},{"content":"Jan 2019 - Dec 2022\nDescription Improved data accuracy by 20%, enabling robust data management. Analyzed large datasets using statistical techniques, enhancing data-driven decisions for partners and customers. Identified trends and correlations in complex data, visualized insights, and supported strategic decision-making. Delivered 10+ monthly reports by compiling data, updating spreadsheets, and conducting research. Resolved data collection and reporting bugs, reducing errors by 15% through root cause analysis. ","permalink":"https://piktx.github.io/experience/datadrive/","summary":"\u003cp\u003e\u003cem\u003eJan 2019 - Dec 2022\u003c/em\u003e\u003c/p\u003e\n\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eImproved data accuracy by \u003cstrong\u003e20%\u003c/strong\u003e, enabling robust data management.\u003c/li\u003e\n\u003cli\u003eAnalyzed large datasets using statistical techniques, enhancing data-driven decisions for partners and customers.\u003c/li\u003e\n\u003cli\u003eIdentified trends and correlations in complex data, visualized insights, and supported strategic decision-making.\u003c/li\u003e\n\u003cli\u003eDelivered \u003cstrong\u003e10+ monthly reports\u003c/strong\u003e by compiling data, updating spreadsheets, and conducting research.\u003c/li\u003e\n\u003cli\u003eResolved data collection and reporting bugs, reducing errors by \u003cstrong\u003e15%\u003c/strong\u003e through root cause analysis.\u003c/li\u003e\n\u003c/ul\u003e","title":"Data Analyst"}]