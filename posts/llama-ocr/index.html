<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Extract Text from Images using Llama OCR | PKT</title>
<meta name="keywords" content="OCR, AI, Llama3.2 Vision, Streamlit, Python">
<meta name="description" content="A step-by-step guide on building an image-to-text extraction tool using Llama 3.2 Vision and Streamlit locally.">
<meta name="author" content="PKT">
<link rel="canonical" href="https://piktx.github.io/posts/llama-ocr/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://piktx.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://piktx.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://piktx.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://piktx.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://piktx.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://piktx.github.io/posts/llama-ocr/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://piktx.github.io/posts/llama-ocr/">
  <meta property="og:site_name" content="PKT">
  <meta property="og:title" content="Extract Text from Images using Llama OCR">
  <meta property="og:description" content="A step-by-step guide on building an image-to-text extraction tool using Llama 3.2 Vision and Streamlit locally.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-02-09T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-02-09T00:00:00+00:00">
    <meta property="article:tag" content="OCR">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Llama3.2 Vision">
    <meta property="article:tag" content="Streamlit">
    <meta property="article:tag" content="Python">
    <meta property="og:image" content="https://piktx.github.io/posts/llama_ocr/llama_ocr.jpeg">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://piktx.github.io/posts/llama_ocr/llama_ocr.jpeg">
<meta name="twitter:title" content="Extract Text from Images using Llama OCR">
<meta name="twitter:description" content="A step-by-step guide on building an image-to-text extraction tool using Llama 3.2 Vision and Streamlit locally.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "https://piktx.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Extract Text from Images using Llama OCR",
      "item": "https://piktx.github.io/posts/llama-ocr/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Extract Text from Images using Llama OCR",
  "name": "Extract Text from Images using Llama OCR",
  "description": "A step-by-step guide on building an image-to-text extraction tool using Llama 3.2 Vision and Streamlit locally.",
  "keywords": [
    "OCR", "AI", "Llama3.2 Vision", "Streamlit", "Python"
  ],
  "articleBody": "Hi everyone (if someoneâ€™s there). Extracting text from images has never been easier, thanks to advanced AI models like Llama 3.2 Vision. In this guide, weâ€™ll walk through building a simple yet powerful OCR (Optical Character Recognition) tool using Python, Streamlit, and Ollamaâ€™s AI models.\nWhy Use Llama 3.2 Vision for OCR? Unlike traditional OCR methods, which rely on predefined character recognition techniques, Llama 3.2 Vision leverages AI to not only extract text but also present it in a structured and readable format. This means better accuracy, automatic formatting, and ease of use.\nUnderstanding the Code This application is built using Streamlit, making it interactive and user-friendly and easy to run locally. Letâ€™s break down how it works:\nConfiguring the Streamlit Page We start by defining the page title, icon, and layout:\nst.set_page_config( page_title=\"Llama OCR\", page_icon=\"ðŸ¦™\", layout=\"wide\", initial_sidebar_state=\"expanded\" ) This ensures a wide layout with an expanded sidebar, making navigation smooth.\nUploading an Image Users can upload images through the sidebar. Weâ€™ll use st.file_uploader() to allow image selection.\nuploaded_file = st.file_uploader(\"Choose an image...\", type=['png', 'jpg', 'jpeg']) Once an image is uploaded, itâ€™s displayed in the sidebar using:\nimage = Image.open(uploaded_file) st.image(image, caption=\"Uploaded Image\") Extracting Text from the Image When the user clicks the Extract Text button, the image is sent to the Llama 3.2 Vision model for processing:\nresponse = ollama.chat( model='llama3.2-vision', messages=[{ 'role': 'user', 'content': \"\"\"Analyze the text in the provided image. Extract all readable content and present it in a structured Markdown format.\"\"\", 'images': [uploaded_file.getvalue()] }] ) The extracted text is stored in st.session_state so it persists across interactions.\nDisplaying the Extracted Text Once the processing is complete, the extracted text is displayed in the main content area using:\nst.markdown(st.session_state['ocr_result']) If no text has been extracted yet, an informational message guides the user.\nRunning the Application locally Run these following commands in your terminal:\nClone the repository: git clone https://github.com/piktx/local-ocr.git cd local-ocr Install dependencies: pip install -r requirements.txt Start Ollama service: ollama serve Launch the Streamlit app: streamlit run app.py This will start a local server, and the tool will be accessible via the displayed URL (usually http://localhost:8501). Final Thoughts With just a few lines of code, you can built an AI-powered OCR tool that can extract structured text from images with impressive accuracy and the best part is, you can do all this on your local machine. Whether you need to digitize documents, extract notes, or process scanned images, Llama 3.2 Vision provides a seamless solution.\nLast but not the least, If you liked this project, donâ€™t forget to give it a star on Github\n",
  "wordCount" : "428",
  "inLanguage": "en",
  "image":"https://piktx.github.io/posts/llama_ocr/llama_ocr.jpeg","datePublished": "2025-02-09T00:00:00Z",
  "dateModified": "2025-02-09T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "PKT"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://piktx.github.io/posts/llama-ocr/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "PKT",
    "logo": {
      "@type": "ImageObject",
      "url": "https://piktx.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://piktx.github.io/" accesskey="h" title="PKT (Alt + H)">PKT</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://piktx.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://piktx.github.io/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://piktx.github.io/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://piktx.github.io/experience" title="Experience">
                    <span>Experience</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://piktx.github.io/">Home</a>&nbsp;Â»&nbsp;<a href="https://piktx.github.io/posts/">Blogs</a></div>
    <h1 class="post-title entry-hint-parent">
      Extract Text from Images using Llama OCR
    </h1>
    <div class="post-description">
      A step-by-step guide on building an image-to-text extraction tool using Llama 3.2 Vision and Streamlit locally.
    </div>
    <div class="post-meta"><span title='2025-02-09 00:00:00 +0000 UTC'>February 9, 2025</span>&nbsp;Â·&nbsp;3 min&nbsp;Â·&nbsp;PKT

</div>
  </header> 
<figure class="entry-cover"><img loading="eager" src="https://piktx.github.io/posts/llama_ocr/llama_ocr.jpeg" alt="">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#why-use-llama-32-vision-for-ocr" aria-label="Why Use Llama 3.2 Vision for OCR?">Why Use Llama 3.2 Vision for OCR?</a></li></ul>
                    
                <li>
                    <a href="#understanding-the-code" aria-label="Understanding the Code">Understanding the Code</a><ul>
                        
                <li>
                    <a href="#configuring-the-streamlit-page" aria-label="Configuring the Streamlit Page">Configuring the Streamlit Page</a></li>
                <li>
                    <a href="#uploading-an-image" aria-label="Uploading an Image">Uploading an Image</a></li>
                <li>
                    <a href="#extracting-text-from-the-image" aria-label="Extracting Text from the Image">Extracting Text from the Image</a></li>
                <li>
                    <a href="#displaying-the-extracted-text" aria-label="Displaying the Extracted Text">Displaying the Extracted Text</a></li></ul>
                </li>
                <li>
                    <a href="#running-the-application-locally" aria-label="Running the Application locally">Running the Application locally</a></li>
                <li>
                    <a href="#final-thoughts" aria-label="Final Thoughts">Final Thoughts</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Hi everyone (if someone&rsquo;s there). Extracting text from images has never been easier, thanks to advanced AI models like Llama 3.2 Vision. In this guide, weâ€™ll walk through building a simple yet powerful OCR (Optical Character Recognition) tool using Python, Streamlit, and Ollamaâ€™s AI models.</p>
<h3 id="why-use-llama-32-vision-for-ocr">Why Use Llama 3.2 Vision for OCR?<a hidden class="anchor" aria-hidden="true" href="#why-use-llama-32-vision-for-ocr">#</a></h3>
<p>Unlike traditional OCR methods, which rely on predefined character recognition techniques, Llama 3.2 Vision leverages AI to not only extract text but also present it in a structured and readable format. This means better accuracy, automatic formatting, and ease of use.</p>
<h2 id="understanding-the-code">Understanding the Code<a hidden class="anchor" aria-hidden="true" href="#understanding-the-code">#</a></h2>
<p>This application is built using Streamlit, making it interactive and user-friendly and easy to run locally. Letâ€™s break down how it works:</p>
<h3 id="configuring-the-streamlit-page">Configuring the Streamlit Page<a hidden class="anchor" aria-hidden="true" href="#configuring-the-streamlit-page">#</a></h3>
<p>We start by defining the page title, icon, and layout:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>st<span style="color:#f92672">.</span>set_page_config(
</span></span><span style="display:flex;"><span>    page_title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Llama OCR&#34;</span>,
</span></span><span style="display:flex;"><span>    page_icon<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ðŸ¦™&#34;</span>,
</span></span><span style="display:flex;"><span>    layout<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;wide&#34;</span>,
</span></span><span style="display:flex;"><span>    initial_sidebar_state<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;expanded&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>This ensures a wide layout with an expanded sidebar, making navigation smooth.</p>
<h3 id="uploading-an-image">Uploading an Image<a hidden class="anchor" aria-hidden="true" href="#uploading-an-image">#</a></h3>
<p>Users can upload images through the sidebar. We&rsquo;ll use <code>st.file_uploader()</code> to allow image selection.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>uploaded_file <span style="color:#f92672">=</span> st<span style="color:#f92672">.</span>file_uploader(<span style="color:#e6db74">&#34;Choose an image...&#34;</span>, type<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;png&#39;</span>, <span style="color:#e6db74">&#39;jpg&#39;</span>, <span style="color:#e6db74">&#39;jpeg&#39;</span>])
</span></span></code></pre></div><p>Once an image is uploaded, itâ€™s displayed in the sidebar using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(uploaded_file)
</span></span><span style="display:flex;"><span>st<span style="color:#f92672">.</span>image(image, caption<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Uploaded Image&#34;</span>)
</span></span></code></pre></div><h3 id="extracting-text-from-the-image">Extracting Text from the Image<a hidden class="anchor" aria-hidden="true" href="#extracting-text-from-the-image">#</a></h3>
<p>When the user clicks the <strong>Extract Text</strong> button, the image is sent to the Llama 3.2 Vision model for processing:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>response <span style="color:#f92672">=</span> ollama<span style="color:#f92672">.</span>chat(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;llama3.2-vision&#39;</span>,
</span></span><span style="display:flex;"><span>    messages<span style="color:#f92672">=</span>[{
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;role&#39;</span>: <span style="color:#e6db74">&#39;user&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;content&#39;</span>: <span style="color:#e6db74">&#34;&#34;&#34;Analyze the text in the provided image. Extract all readable content
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    and present it in a structured Markdown format.&#34;&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;images&#39;</span>: [uploaded_file<span style="color:#f92672">.</span>getvalue()]
</span></span><span style="display:flex;"><span>    }]
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>The extracted text is stored in <code>st.session_state</code> so it persists across interactions.</p>
<h3 id="displaying-the-extracted-text">Displaying the Extracted Text<a hidden class="anchor" aria-hidden="true" href="#displaying-the-extracted-text">#</a></h3>
<p>Once the processing is complete, the extracted text is displayed in the main content area using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>st<span style="color:#f92672">.</span>markdown(st<span style="color:#f92672">.</span>session_state[<span style="color:#e6db74">&#39;ocr_result&#39;</span>])
</span></span></code></pre></div><p>If no text has been extracted yet, an informational message guides the user.</p>
<h2 id="running-the-application-locally">Running the Application locally<a hidden class="anchor" aria-hidden="true" href="#running-the-application-locally">#</a></h2>
<p>Run these following commands in your terminal:</p>
<ol>
<li>Clone the repository:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone https://github.com/piktx/local-ocr.git
</span></span><span style="display:flex;"><span>cd local-ocr
</span></span></code></pre></div><ol start="2">
<li>Install dependencies:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>pip install -r requirements.txt
</span></span></code></pre></div><ol start="3">
<li>Start Ollama service:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ollama serve
</span></span></code></pre></div><ol start="4">
<li>Launch the Streamlit app:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>streamlit run app.py
</span></span></code></pre></div><p>This will start a local server, and the tool will be accessible via the displayed URL (usually <code>http://localhost:8501</code>).
<img loading="lazy" src="/projects/llama_ocr/local_ocr.png"></p>
<h2 id="final-thoughts">Final Thoughts<a hidden class="anchor" aria-hidden="true" href="#final-thoughts">#</a></h2>
<p>With just a few lines of code, you can built an AI-powered OCR tool that can extract structured text from images with impressive accuracy and the best part is, you can do all this on your local machine. Whether you need to digitize documents, extract notes, or process scanned images, Llama 3.2 Vision provides a seamless solution.</p>
<p>Last but not the least, If you liked this project, don&rsquo;t forget to give it a <strong>star</strong> on <strong><a href="https://github.com/piktx/local-ocr">Github</a></strong></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://piktx.github.io/tags/ocr/">OCR</a></li>
      <li><a href="https://piktx.github.io/tags/ai/">AI</a></li>
      <li><a href="https://piktx.github.io/tags/llama3.2-vision/">Llama3.2 Vision</a></li>
      <li><a href="https://piktx.github.io/tags/streamlit/">Streamlit</a></li>
      <li><a href="https://piktx.github.io/tags/python/">Python</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://piktx.github.io/posts/gemini-flash-chatbot/">
    <span class="title">Next Â»</span>
    <br>
    <span>Building Conversational AI Experiences: From Spreadsheets to Multimodal Magic</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Extract Text from Images using Llama OCR on x"
            href="https://x.com/intent/tweet/?text=Extract%20Text%20from%20Images%20using%20Llama%20OCR&amp;url=https%3a%2f%2fpiktx.github.io%2fposts%2fllama-ocr%2f&amp;hashtags=OCR%2cAI%2cLlama3.2Vision%2cStreamlit%2cPython">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Extract Text from Images using Llama OCR on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpiktx.github.io%2fposts%2fllama-ocr%2f&amp;title=Extract%20Text%20from%20Images%20using%20Llama%20OCR&amp;summary=Extract%20Text%20from%20Images%20using%20Llama%20OCR&amp;source=https%3a%2f%2fpiktx.github.io%2fposts%2fllama-ocr%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Extract Text from Images using Llama OCR on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fpiktx.github.io%2fposts%2fllama-ocr%2f&title=Extract%20Text%20from%20Images%20using%20Llama%20OCR">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Extract Text from Images using Llama OCR on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpiktx.github.io%2fposts%2fllama-ocr%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Extract Text from Images using Llama OCR on whatsapp"
            href="https://api.whatsapp.com/send?text=Extract%20Text%20from%20Images%20using%20Llama%20OCR%20-%20https%3a%2f%2fpiktx.github.io%2fposts%2fllama-ocr%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Extract Text from Images using Llama OCR on telegram"
            href="https://telegram.me/share/url?text=Extract%20Text%20from%20Images%20using%20Llama%20OCR&amp;url=https%3a%2f%2fpiktx.github.io%2fposts%2fllama-ocr%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Extract Text from Images using Llama OCR on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Extract%20Text%20from%20Images%20using%20Llama%20OCR&u=https%3a%2f%2fpiktx.github.io%2fposts%2fllama-ocr%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://piktx.github.io/">PKT</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
